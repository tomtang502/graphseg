{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/graphseg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/tomriva/graphseg/third_party/dust3r\n",
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import torch, glob, os\n",
    "import numpy as np\n",
    "from src.helpers.data_process import read_pkl\n",
    "from PIL import Image\n",
    "from rgb_demo import main\n",
    "\n",
    "def read_biarm_imgs(directory):\n",
    "    \"\"\"\n",
    "    Load can_left and can_right images from a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): The path to the directory containing the image files.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists containing numpy arrays of the can_left and can_right images, respectively.\n",
    "    \"\"\"\n",
    "    # Build file patterns with the directory name\n",
    "    left_pattern = os.path.join(directory, \"can_left_*.png\")\n",
    "    right_pattern = os.path.join(directory, \"can_right_*.png\")\n",
    "\n",
    "    # Retrieve and sort file paths\n",
    "    left_paths = sorted(glob.glob(left_pattern))\n",
    "    right_paths = sorted(glob.glob(right_pattern))\n",
    "\n",
    "    # Open each image and convert it into a numpy array\n",
    "    left_images = np.stack([np.array(Image.open(path)) for path in left_paths])\n",
    "    right_images = np.stack([np.array(Image.open(path)) for path in right_paths])\n",
    "\n",
    "    return left_images, right_images\n",
    "\n",
    "def ensure_stacked(x):\n",
    "    \"\"\"\n",
    "    If x is a list of tensors, stack them along a new 0-dim and return the tensor.\n",
    "    Otherwise, return x unchanged.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        # assumes each element of x is a torch.Tensor of the same shape\n",
    "        return torch.stack(x, dim=0)\n",
    "    return x\n",
    "\n",
    "def read_biarm_data_rev(data_dir, n_imgs_per_side, factor=1000):\n",
    "    left_eef_poses_file = f\"{data_dir}/can_left_poses.pt\"\n",
    "    right_eef_poses_file = f\"{data_dir}/can_right_poses.pt\"\n",
    "    \n",
    "    left_eef_poses = ensure_stacked(torch.load(left_eef_poses_file, weights_only=False))\n",
    "    right_eef_poses = ensure_stacked(torch.load(right_eef_poses_file, weights_only=False))\n",
    "    l, r = read_biarm_imgs(data_dir)\n",
    "    \n",
    "    \n",
    "    l = l[:len(left_eef_poses)]\n",
    "    r = r[:len(right_eef_poses)]\n",
    "    # print(l.shape, r.shape, left_eef_poses.shape, right_eef_poses.shape)\n",
    "    right_eef_poses[:, 3:] /= factor\n",
    "    left_eef_poses[:, 3:] /= factor\n",
    "    return l[-n_imgs_per_side:], left_eef_poses[-n_imgs_per_side:], r[-n_imgs_per_side:], right_eef_poses[-n_imgs_per_side:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3087322 3145728\n"
     ]
    }
   ],
   "source": [
    "n_imgs_per_side = 8\n",
    "exp_name = 3\n",
    "data_dir = f\"../genJCR_light/data/data_3/{exp_name}\"\n",
    "genjcr_res_path = f\"../genJCR_light/output/data_3/{exp_name}_{n_imgs_per_side}_gjcr.pth\"\n",
    "res_dict = read_pkl(genjcr_res_path)\n",
    "conf_mask = res_dict['conf_masks'].reshape(-1,)\n",
    "xyz = res_dict['xyzs'].numpy().reshape(-1, 3)[conf_mask]        # (n,3)\n",
    "print(len(xyz), len(res_dict['xyzs'].reshape(-1, 3)))\n",
    "rgb = res_dict['rgbs'].reshape(-1, 3)[conf_mask] # (n,3)  uint8 0–255\n",
    "left_imgs, left_eef_poses, right_imgs, right_eef_poses = read_biarm_data_rev(data_dir=data_dir, n_imgs_per_side=n_imgs_per_side)\n",
    "\n",
    "all_imgs = np.concatenate((left_imgs, right_imgs))\n",
    "all_poses = torch.concatenate((left_eef_poses, right_eef_poses))\n",
    "cam_poses = res_dict['cam_poses']    # (m,4,4) camera→world, already numpy\n",
    "eef_poses = res_dict['eef_poses'].numpy() # (m,4,4) eef->world\n",
    "br2bl = res_dict['br2bl'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 480, 640, 3) (16, 384, 512, 3) torch.Size([16, 384, 512, 3]) (16, 4, 4) torch.Size([16, 384, 512])\n",
      "Step 1: [Segmentation]\n",
      "After [1]: 960.62 MiB / 40960.00 MiB used\n",
      "Step 2: [FM]\n",
      "After [2]: 982.62 MiB / 40960.00 MiB used\n",
      "Step 3: [BG Masks]\n",
      "Step 4: [GC]\n",
      "seg_group_thresh: 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "main(rgbs_o=all_imgs, xyzs=res_dict['xyzs'], rgbs=res_dict['rgbs'], conf_3d_masks=res_dict['conf_masks'].cuda(), poses=cam_poses, save_name=exp_name, rerun_anyway=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
